import streamlit as st
import os
import openai  # OpenAI API for embeddings
import pinecone  # Pinecone for vector storage
import fitz  # PyMuPDF for PDF text and annotation extraction
import hashlib # Used for generating unique document IDs
import datetime # For timestamp-based naming
import json  # For handling annotation metadata

# ‚úÖ Load API keys from Streamlit Secrets
OPENAI_API_KEY = st.secrets["OPENAI"]
PINECONE_API_KEY = st.secrets["PINECONE"]

# ‚úÖ Configure Pinecone
PINECONE_ENV = "us-east-1"  # Pinecone region
INDEX_NAME = "ample-traffic"  # Pinecone index name

# ‚úÖ Initialize Pinecone
pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)

# ‚úÖ OpenAI Embeddings Configuration
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)

# ‚úÖ Ensure the "temp" directory exists
TEMP_DIR = "temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ‚úÖ Function to Extract Text & Annotations from PDFs
def extract_text_from_pdf(pdf_file):
    """Extracts text and annotations from a PDF file."""
    text = []
    annotations = []

    with fitz.open(pdf_file) as doc:
        for page in doc:
            text.append(page.get_text())  # Extracts page text
            for annot in page.annots():  # Extracts annotations
                if annot:
                    annotations.append(annot.info["content"])

    return " ".join(text), " ".join(annotations)

# ‚úÖ Function to Process & Store Documents in Pinecone
def process_and_store(uploaded_file, file_type):
    """Processes the uploaded PDF and stores embeddings in Pinecone."""
    if uploaded_file is None:
        return

    # üîπ Generate Unique Project Name
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    project_name = f"{file_type}_{timestamp}"

    # üîπ Save Uploaded File Temporarily
    file_path = f"temp_{project_name}.pdf"
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # üîπ Extract Text and Annotations
    extracted_text, extracted_annotations = extract_text_from_pdf(file_path)

    # üîπ Generate Embeddings (Fixed Extraction)
    response = openai_client.embeddings.create(
        input=extracted_text + " " + extracted_annotations,
        model="text-embedding-ada-002"
    )
    embedding_vector = response.data[0].embedding  # ‚úÖ FIXED

  # üîπ Store in Pinecone (Now Includes Project Name in Metadata)
    doc_id = hashlib.md5((project_name + file_type).encode()).hexdigest()
    index.upsert(
        vectors=[
            (
                doc_id,
                embedding_vector,
                {
                    "text": extracted_text,
                    "annotations": extracted_annotations,
                    "project_name": project_name,  # ‚úÖ NEW: Adds project name
                    "file_type": file_type,
                },
            )
        ]
    )

    # ‚úÖ Success Message
    st.success(f"‚úÖ {file_type} for project '{project_name}' successfully stored in Pinecone!")
# ‚úÖ Streamlit UI
st.title("üö¶ Traffic Study Learning")
st.write("Upload traffic study documents. The app will extract text & annotations and store them in a vector database.")

# **üîπ Enter Project Name**
project_name = st.text_input("Enter Project Name:")

# **üîπ Upload Files**
raw_study = st.file_uploader("Upload Raw Traffic Study", type=["pdf"])
annotated_study = st.file_uploader("Upload Annotated Traffic Study", type=["pdf"])
review_letter = st.file_uploader("Upload Final Review Letter", type=["pdf"])

# **üîπ Process & Store in Pinecone**
if st.button("Store in Vector Database"):
    if project_name:
        process_and_store(raw_study, "Raw Study", project_name)
        process_and_store(annotated_study, "Annotations", project_name)
        process_and_store(review_letter, "Review Letter", project_name)
    else:
         st.error("‚ùå Please enter a project name before storing data.")
